{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49fe545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a362ac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension of input\n",
    "dims = 80\n",
    "\n",
    "signal_length = 100\n",
    "signal_repeats = 3\n",
    "predict_ahead = 1\n",
    "noise_strength = 0.03\n",
    "total_series_length = signal_length * signal_repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c823759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData(dims, signal_length, predict_ahead, \n",
    "                 signal_repeats, batch_size, noise_strength):\n",
    "    total_series_length = signal_length * signal_repeats\n",
    "    time = np.linspace(\n",
    "        0, np.pi*2*signal_repeats, \n",
    "        total_series_length * dims + predict_ahead * dims, dtype=np.float32\n",
    "    )\n",
    "    time = time.reshape((1, -1, dims))  \n",
    "    \n",
    "    # include shift for batches\n",
    "    time = np.repeat(time, batch_size, 0)\n",
    "    time += np.random.random(batch_size)[:, None, None] * 10\n",
    "    y = np.sin(time)\n",
    "    input_ = y[:, :total_series_length, :].copy()\n",
    "    if noise_strength > 0:\n",
    "        input_ += np.random.normal(size=(input_.shape)) * noise_strength # add some noise to the input\n",
    "    target = y[:, predict_ahead:, :]\n",
    "    return torch.tensor(input_) , torch.tensor(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88453724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, define our model and initialize the learnable weights and biases (parameters):\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, dims, hidden_dims,\n",
    "                 learn_h0=False, learn_c0=False,\n",
    "                 activation_h=nn.Tanh,\n",
    "                 activation_o=nn.Sigmoid, activation_f=nn.Tanh, \n",
    "                 activation_i=nn.Sigmoid, activation_j=nn.Sigmoid, \n",
    "                 rnn_mode=True):\n",
    "        super().__init__()\n",
    "        # it is fine to hard code these \n",
    "        self.activation_h = activation_h()\n",
    "        self.activation_o = activation_o()\n",
    "        self.activation_f = activation_f()\n",
    "        self.activation_i = activation_i()\n",
    "        self.activation_j = activation_j()\n",
    "        \n",
    "        # parameters of the (recurrent) hidden layer\n",
    "        self.W_o = nn.Parameter(torch.randn(dims, hidden_dims) * .1)\n",
    "        self.b_o = nn.Parameter(torch.zeros(1, hidden_dims))\n",
    "        self.W_f = nn.Parameter(torch.randn(dims, hidden_dims) * .1)\n",
    "        self.b_f = nn.Parameter(torch.zeros(1, hidden_dims))\n",
    "        self.W_i = nn.Parameter(torch.randn(dims, hidden_dims) * .1)\n",
    "        self.b_i = nn.Parameter(torch.zeros(1, hidden_dims))\n",
    "        self.W_j = nn.Parameter(torch.randn(dims, hidden_dims) * .1)\n",
    "        self.b_j = nn.Parameter(torch.zeros(1, hidden_dims))\n",
    "        \n",
    "        \n",
    "        self.U_o = nn.Parameter(\n",
    "            torch.randn(hidden_dims, hidden_dims) * .1\n",
    "        )\n",
    "        self.U_f = nn.Parameter(\n",
    "            torch.randn(hidden_dims, hidden_dims) * .1\n",
    "        )\n",
    "        self.U_i = nn.Parameter(\n",
    "            torch.randn(hidden_dims, hidden_dims) * .1\n",
    "        )\n",
    "        self.U_j = nn.Parameter(\n",
    "            torch.randn(hidden_dims, hidden_dims) * .1\n",
    "        )\n",
    "        \n",
    "        if not rnn_mode:\n",
    "            self.U_o.zero_(); self.U_f.zero_(); self.U_i.zero_(); self.U_j.zero_()\n",
    "            self.U_o.requires_grad = False\n",
    "            self.U_f.requires_grad = False\n",
    "            self.U_i.requires_grad = False\n",
    "            self.U_j.requires_grad = False\n",
    "\n",
    "        # initial hidden state\n",
    "        self.h_0 = nn.Parameter(\n",
    "            torch.zeros(1, hidden_dims),\n",
    "            requires_grad=learn_h0 # only train this if enabled\n",
    "        )        \n",
    "        \n",
    "        # initial cell state\n",
    "        self.c_0 = nn.Parameter(\n",
    "            torch.zeros(1, hidden_dims),\n",
    "            requires_grad=learn_c0 # only train this if enabled\n",
    "        )\n",
    "        \n",
    "        # output layer (fully connected)\n",
    "        self.W_y = nn.Parameter(torch.randn(hidden_dims, dims) * .1)\n",
    "        self.b_y = nn.Parameter(torch.zeros(1, dims))\n",
    "                \n",
    "    def step(self, x_t, h, c):\n",
    "        #  forward pass for a single time step\n",
    "        # hint: a more clever implementation could combine all these and select the different parts later\n",
    "        j = self.activation_j(\n",
    "            torch.matmul(x_t, self.W_j) + torch.matmul(h, self.U_j) + self.b_j\n",
    "        )\n",
    "        i = self.activation_i(\n",
    "            torch.matmul(x_t, self.W_i) + torch.matmul(h, self.U_i) + self.b_i\n",
    "        )\n",
    "        f = self.activation_f(\n",
    "            torch.matmul(x_t, self.W_f) + torch.matmul(h, self.U_f) + self.b_f\n",
    "        )        \n",
    "        o = self.activation_o(\n",
    "            torch.matmul(x_t, self.W_o) + torch.matmul(h, self.U_o) + self.b_o\n",
    "        )\n",
    "        \n",
    "        \n",
    "        c = f * c + i * j\n",
    "        \n",
    "        h = o * self.activation_h(c)\n",
    "\n",
    "        return h, c # returning new hidden and cell state\n",
    "\n",
    "    def iterate_series(self, x, h, c):\n",
    "        # apply rnn to each time step and give an output (many-to-many task)\n",
    "        batch_size, n_steps, dimensions = x.shape\n",
    "        \n",
    "        # can use cell states list here but only the last cell is required\n",
    "        hidden_states = []\n",
    "        # iterate over time axis (1)\n",
    "        for t in range(n_steps):\n",
    "            # give previous hidden state and input from the current time step\n",
    "            h, c = self.step(x[:, t], h, c)\n",
    "            hidden_states.append(h)\n",
    "        hidden_states = torch.stack(hidden_states, 1)\n",
    "        \n",
    "        # fully connected output\n",
    "        y_hat = hidden_states.reshape(batch_size * n_steps, -1) # flatten steps and batch size (bs * )\n",
    "        y_hat = torch.matmul(y_hat, self.W_y) + self.b_y\n",
    "        y_hat = y_hat.reshape(batch_size, n_steps, -1) # regains structure\n",
    "        return y_hat, hidden_states[:, -1], c\n",
    "    \n",
    "    def forward(self, x, h, c):\n",
    "        # x: b, t, d\n",
    "        batch_size = x.shape[0] \n",
    "        if h is None:\n",
    "            h = self.h_0.repeat_interleave(batch_size, 0)\n",
    "        if c is None:\n",
    "            c = self.c_0.repeat_interleave(batch_size, 0)\n",
    "        y_hat, h, c = self.iterate_series(x, h, c)\n",
    "        return y_hat, h, c\n",
    "    \n",
    "    def auto_regression(self, x_0, h, c, steps):\n",
    "        # one-to-many task (steps = \\delta')\n",
    "        x_prev = x_0\n",
    "        y_hat = []\n",
    "        # iterate over time axis (1)\n",
    "        for t in range(steps):\n",
    "            # give previous hidden state and input from the current time step\n",
    "            h, c = self.step(x_prev, h, c)\n",
    "            # here we need to apply the output layer on each step individually\n",
    "            x_prev = torch.matmul(h, self.W_y) + self.b_y\n",
    "            \n",
    "            y_hat.append(x_prev)\n",
    "        y_hat = torch.stack(y_hat, 1)\n",
    "        return y_hat, h, c\n",
    "    \n",
    "    def many_to_one(self, x, h, c):\n",
    "        # not required\n",
    "        # returns the last prediction and the hidden state\n",
    "        y_hat, h, c = self(x, h, c)\n",
    "        return y_hat[:, -1], h, c # only return the last prediction\n",
    "        \n",
    "    def many_to_many_async(self, x, h, c, steps):\n",
    "        # not required\n",
    "        # combines many-to-one and one-to-many\n",
    "        x_0, h, c = self.many_to_one(x, h, c)\n",
    "        return self.auto_regression(x_0, h, c, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7befc22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the hidden state (True) by activating learning for U_h\n",
    "rnn_mode = True\n",
    "# learn a better initial hidden state representation (True) than zero init\n",
    "learn_h0 = True\n",
    "\n",
    "# number of weight update iterations\n",
    "n_iterations = 25 #250\n",
    "\n",
    "# number of neurons m in the hidden layer\n",
    "num_neurons = 256\n",
    "batch_size  = 1024 #should be 1024\n",
    "lr = 0.01\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c872394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = LSTM(\n",
    "    dims, num_neurons, \n",
    "    learn_h0=learn_h0, \n",
    "    rnn_mode=rnn_mode\n",
    ")\n",
    "rnn.to(device)\n",
    "\n",
    "# standard optimizer SGD or AdaGrad would also work\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ee1f6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10665.236328125\n",
      "tensor([[-1.3177e-03, -1.9459e-03,  4.3758e-05,  ..., -9.1291e-04,\n",
      "          8.9039e-04, -1.2779e-03],\n",
      "        [-1.3176e-03, -1.9456e-03,  4.3681e-05,  ..., -9.1271e-04,\n",
      "          8.9052e-04, -1.2780e-03],\n",
      "        [-1.3175e-03, -1.9453e-03,  4.3692e-05,  ..., -9.1255e-04,\n",
      "          8.9077e-04, -1.2780e-03],\n",
      "        ...,\n",
      "        [-1.3233e-03, -1.9378e-03,  4.8259e-05,  ..., -9.1218e-04,\n",
      "          8.9163e-04, -1.2849e-03],\n",
      "        [-1.3229e-03, -1.9371e-03,  4.8118e-05,  ..., -9.1186e-04,\n",
      "          8.9157e-04, -1.2844e-03],\n",
      "        [-1.3231e-03, -1.9372e-03,  4.8297e-05,  ..., -9.1183e-04,\n",
      "          8.9134e-04, -1.2847e-03]])\n",
      "20965.748046875\n",
      "tensor([[-1.3305e-04,  2.3059e-04,  1.4933e-03,  ..., -6.2801e-06,\n",
      "         -5.0394e-05, -7.2931e-04],\n",
      "        [-1.3308e-04,  2.3065e-04,  1.4931e-03,  ..., -6.2312e-06,\n",
      "         -5.0394e-05, -7.2953e-04],\n",
      "        [-1.3308e-04,  2.3085e-04,  1.4932e-03,  ..., -6.1965e-06,\n",
      "         -5.0417e-05, -7.2967e-04],\n",
      "        ...,\n",
      "        [-1.3309e-04,  2.3304e-04,  1.4858e-03,  ..., -3.7330e-06,\n",
      "         -5.0444e-05, -7.3588e-04],\n",
      "        [-1.3308e-04,  2.3300e-04,  1.4856e-03,  ..., -3.6975e-06,\n",
      "         -5.0442e-05, -7.3602e-04],\n",
      "        [-1.3311e-04,  2.3297e-04,  1.4859e-03,  ..., -3.6382e-06,\n",
      "         -5.0468e-05, -7.3616e-04]])\n",
      "5705.1552734375\n",
      "tensor([[ 1.3048e-06, -3.9274e-04, -5.6348e-07,  ..., -2.2556e-05,\n",
      "          8.9154e-06,  7.8460e-05],\n",
      "        [ 1.2875e-06, -3.9278e-04, -5.6922e-07,  ..., -2.2533e-05,\n",
      "          8.9143e-06,  7.8166e-05],\n",
      "        [ 1.2954e-06, -3.9247e-04, -6.4369e-07,  ..., -2.2492e-05,\n",
      "          8.9005e-06,  7.7992e-05],\n",
      "        ...,\n",
      "        [ 9.6697e-07, -3.8040e-04, -8.8783e-06,  ..., -2.0210e-05,\n",
      "          8.2294e-06,  6.0667e-05],\n",
      "        [ 9.7012e-07, -3.8007e-04, -8.8804e-06,  ..., -2.0170e-05,\n",
      "          8.2148e-06,  6.0572e-05],\n",
      "        [ 9.6670e-07, -3.7998e-04, -9.0693e-06,  ..., -2.0124e-05,\n",
      "          8.1915e-06,  6.0253e-05]])\n",
      "4632.0009765625\n",
      "tensor([[ 1.9200e-04, -1.3812e-04, -5.0935e-04,  ..., -5.3901e-05,\n",
      "          1.3692e-05,  3.2829e-04],\n",
      "        [ 1.9200e-04, -1.3807e-04, -5.0949e-04,  ..., -5.3868e-05,\n",
      "          1.3699e-05,  3.2800e-04],\n",
      "        [ 1.9202e-04, -1.3788e-04, -5.0952e-04,  ..., -5.3858e-05,\n",
      "          1.3679e-05,  3.2791e-04],\n",
      "        ...,\n",
      "        [ 1.9202e-04, -1.2849e-04, -5.1650e-04,  ..., -5.2174e-05,\n",
      "          1.2796e-05,  3.1154e-04],\n",
      "        [ 1.9200e-04, -1.2838e-04, -5.1644e-04,  ..., -5.2170e-05,\n",
      "          1.2795e-05,  3.1144e-04],\n",
      "        [ 1.9195e-04, -1.2828e-04, -5.1641e-04,  ..., -5.2114e-05,\n",
      "          1.2769e-05,  3.1104e-04]])\n",
      "4482.509765625\n",
      "tensor([[ 4.6105e-05, -4.1580e-06, -2.8414e-04,  ..., -4.4356e-06,\n",
      "         -2.0638e-05,  3.0299e-04],\n",
      "        [ 4.6113e-05, -4.0649e-06, -2.8440e-04,  ..., -4.3908e-06,\n",
      "         -2.0655e-05,  3.0285e-04],\n",
      "        [ 4.6148e-05, -3.8803e-06, -2.8441e-04,  ..., -4.3762e-06,\n",
      "         -2.0663e-05,  3.0270e-04],\n",
      "        ...,\n",
      "        [ 4.6426e-05,  2.8686e-06, -2.9286e-04,  ..., -2.7646e-06,\n",
      "         -2.2045e-05,  2.8874e-04],\n",
      "        [ 4.6451e-05,  2.9888e-06, -2.9295e-04,  ..., -2.7383e-06,\n",
      "         -2.2060e-05,  2.8859e-04],\n",
      "        [ 4.6478e-05,  3.1364e-06, -2.9301e-04,  ..., -2.7102e-06,\n",
      "         -2.2082e-05,  2.8840e-04]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b3173cc263e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# get predictions (forward pass)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# calculate mean squared error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-6fc3d6029289>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h, c)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-6fc3d6029289>\u001b[0m in \u001b[0;36miterate_series\u001b[0;34m(self, x, h, c)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# fully connected output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# flatten steps and batch size (bs * )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# regains structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rnn.train()\n",
    "iteration = 0\n",
    "# how often we plot the prediction\n",
    "log_iter = 10\n",
    "iter_loss = []\n",
    "\n",
    "# train for a set number of iterations\n",
    "for iteration in range(n_iterations):\n",
    "\n",
    "    # generates a long time series / normally loaded from dataset (e.g. stocks, weather)\n",
    "    x, y = generateData(\n",
    "        dims, signal_length, predict_ahead, signal_repeats, batch_size, noise_strength\n",
    "    )\n",
    "\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    h = c = None\n",
    "    # reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "#    t0 = time.time()\n",
    "    start.record()\n",
    "\n",
    "    # get predictions (forward pass)\n",
    "    y_hat, h, c = rnn(x, h, c)\n",
    "           \n",
    "    # calculate mean squared error\n",
    "    loss = torch.mean((y_hat - y)**2)        \n",
    "    # backprop\n",
    "    loss.backward()\n",
    "\n",
    "    end.record()\n",
    "#    torch.cuda.current_stream().synchronize()\n",
    "#    t1 = time.time()\n",
    "#    print(t1-t0)\n",
    "\n",
    "    # Waits for everything to finish running\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    print(start.elapsed_time(end))\n",
    "\n",
    "    print(rnn.W_o.grad)\n",
    "    # finally we are adapting the weights with the saved gradient information\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    # log loss\n",
    "#    iter_loss.append(loss.item())\n",
    "    \n",
    "    # plot model predictions during training\n",
    "#    if iteration % log_iter == 0:\n",
    "#        replot(x[0].cpu(), y_hat[0].detach().cpu(), \n",
    "#               y[0].cpu(), iteration + 1, iter_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57763251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db6482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
