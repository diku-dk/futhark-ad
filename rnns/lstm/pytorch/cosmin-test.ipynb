{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49fe545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a362ac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension of input\n",
    "dims = 80\n",
    "\n",
    "signal_length = 100\n",
    "signal_repeats = 3\n",
    "predict_ahead = 1\n",
    "noise_strength = 0.03\n",
    "total_series_length = signal_length * signal_repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c823759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData(dims, signal_length, predict_ahead, \n",
    "                 signal_repeats, batch_size, noise_strength):\n",
    "    total_series_length = signal_length * signal_repeats\n",
    "    time = np.linspace(\n",
    "        0, np.pi*2*signal_repeats, \n",
    "        total_series_length * dims + predict_ahead * dims, dtype=np.float32\n",
    "    )\n",
    "    time = time.reshape((1, -1, dims))  \n",
    "    \n",
    "    # include shift for batches\n",
    "    time = np.repeat(time, batch_size, 0)\n",
    "    time += np.random.random(batch_size)[:, None, None] * 10\n",
    "    y = np.sin(time)\n",
    "    input_ = y[:, :total_series_length, :].copy()\n",
    "    if noise_strength > 0:\n",
    "        input_ += np.random.normal(size=(input_.shape)) * noise_strength # add some noise to the input\n",
    "    target = y[:, predict_ahead:, :]\n",
    "    return torch.tensor(input_) , torch.tensor(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88453724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, define our model and initialize the learnable weights and biases (parameters):\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, dims, hidden_dims,\n",
    "                 learn_h0=False, learn_c0=False,\n",
    "                 activation_h=nn.Tanh,\n",
    "                 activation_o=nn.Sigmoid, activation_f=nn.Tanh, \n",
    "                 activation_i=nn.Sigmoid, activation_j=nn.Sigmoid, \n",
    "                 rnn_mode=True):\n",
    "        super().__init__()\n",
    "        # it is fine to hard code these \n",
    "        self.activation_h = activation_h()\n",
    "        self.activation_o = activation_o()\n",
    "        self.activation_f = activation_f()\n",
    "        self.activation_i = activation_i()\n",
    "        self.activation_j = activation_j()\n",
    "        \n",
    "        # parameters of the (recurrent) hidden layer\n",
    "        self.W_o = nn.Parameter(torch.randn(dims, hidden_dims) * .1)\n",
    "        self.b_o = nn.Parameter(torch.zeros(1, hidden_dims))\n",
    "        self.W_f = nn.Parameter(torch.randn(dims, hidden_dims) * .1)\n",
    "        self.b_f = nn.Parameter(torch.zeros(1, hidden_dims))\n",
    "        self.W_i = nn.Parameter(torch.randn(dims, hidden_dims) * .1)\n",
    "        self.b_i = nn.Parameter(torch.zeros(1, hidden_dims))\n",
    "        self.W_j = nn.Parameter(torch.randn(dims, hidden_dims) * .1)\n",
    "        self.b_j = nn.Parameter(torch.zeros(1, hidden_dims))\n",
    "        \n",
    "        \n",
    "        self.U_o = nn.Parameter(\n",
    "            torch.randn(hidden_dims, hidden_dims) * .1\n",
    "        )\n",
    "        self.U_f = nn.Parameter(\n",
    "            torch.randn(hidden_dims, hidden_dims) * .1\n",
    "        )\n",
    "        self.U_i = nn.Parameter(\n",
    "            torch.randn(hidden_dims, hidden_dims) * .1\n",
    "        )\n",
    "        self.U_j = nn.Parameter(\n",
    "            torch.randn(hidden_dims, hidden_dims) * .1\n",
    "        )\n",
    "        \n",
    "        if not rnn_mode:\n",
    "            self.U_o.zero_(); self.U_f.zero_(); self.U_i.zero_(); self.U_j.zero_()\n",
    "            self.U_o.requires_grad = False\n",
    "            self.U_f.requires_grad = False\n",
    "            self.U_i.requires_grad = False\n",
    "            self.U_j.requires_grad = False\n",
    "\n",
    "        # initial hidden state\n",
    "        self.h_0 = nn.Parameter(\n",
    "            torch.zeros(1, hidden_dims),\n",
    "            requires_grad=learn_h0 # only train this if enabled\n",
    "        )        \n",
    "        \n",
    "        # initial cell state\n",
    "        self.c_0 = nn.Parameter(\n",
    "            torch.zeros(1, hidden_dims),\n",
    "            requires_grad=learn_c0 # only train this if enabled\n",
    "        )\n",
    "        \n",
    "        # output layer (fully connected)\n",
    "        self.W_y = nn.Parameter(torch.randn(hidden_dims, dims) * .1)\n",
    "        self.b_y = nn.Parameter(torch.zeros(1, dims))\n",
    "                \n",
    "    def step(self, x_t, h, c):\n",
    "        #  forward pass for a single time step\n",
    "        # hint: a more clever implementation could combine all these and select the different parts later\n",
    "        j = self.activation_j(\n",
    "            torch.matmul(x_t, self.W_j) + torch.matmul(h, self.U_j) + self.b_j\n",
    "        )\n",
    "        i = self.activation_i(\n",
    "            torch.matmul(x_t, self.W_i) + torch.matmul(h, self.U_i) + self.b_i\n",
    "        )\n",
    "        f = self.activation_f(\n",
    "            torch.matmul(x_t, self.W_f) + torch.matmul(h, self.U_f) + self.b_f\n",
    "        )        \n",
    "        o = self.activation_o(\n",
    "            torch.matmul(x_t, self.W_o) + torch.matmul(h, self.U_o) + self.b_o\n",
    "        )\n",
    "        \n",
    "        \n",
    "        c = f * c + i * j\n",
    "        \n",
    "        h = o * self.activation_h(c)\n",
    "\n",
    "        return h, c # returning new hidden and cell state\n",
    "\n",
    "    def iterate_series(self, x, h, c):\n",
    "        # apply rnn to each time step and give an output (many-to-many task)\n",
    "        batch_size, n_steps, dimensions = x.shape\n",
    "        \n",
    "        # can use cell states list here but only the last cell is required\n",
    "        hidden_states = []\n",
    "        # iterate over time axis (1)\n",
    "        for t in range(n_steps):\n",
    "            # give previous hidden state and input from the current time step\n",
    "            h, c = self.step(x[:, t], h, c)\n",
    "            hidden_states.append(h)\n",
    "        hidden_states = torch.stack(hidden_states, 1)\n",
    "        \n",
    "        # fully connected output\n",
    "        y_hat = hidden_states.reshape(batch_size * n_steps, -1) # flatten steps and batch size (bs * )\n",
    "        y_hat = torch.matmul(y_hat, self.W_y) + self.b_y\n",
    "        y_hat = y_hat.reshape(batch_size, n_steps, -1) # regains structure\n",
    "        return y_hat, hidden_states[:, -1], c\n",
    "    \n",
    "    def forward(self, x, h, c):\n",
    "        # x: b, t, d\n",
    "        batch_size = x.shape[0] \n",
    "        if h is None:\n",
    "            h = self.h_0.repeat_interleave(batch_size, 0)\n",
    "        if c is None:\n",
    "            c = self.c_0.repeat_interleave(batch_size, 0)\n",
    "        y_hat, h, c = self.iterate_series(x, h, c)\n",
    "        return y_hat, h, c\n",
    "    \n",
    "    def auto_regression(self, x_0, h, c, steps):\n",
    "        # one-to-many task (steps = \\delta')\n",
    "        x_prev = x_0\n",
    "        y_hat = []\n",
    "        # iterate over time axis (1)\n",
    "        for t in range(steps):\n",
    "            # give previous hidden state and input from the current time step\n",
    "            h, c = self.step(x_prev, h, c)\n",
    "            # here we need to apply the output layer on each step individually\n",
    "            x_prev = torch.matmul(h, self.W_y) + self.b_y\n",
    "            \n",
    "            y_hat.append(x_prev)\n",
    "        y_hat = torch.stack(y_hat, 1)\n",
    "        return y_hat, h, c\n",
    "    \n",
    "    def many_to_one(self, x, h, c):\n",
    "        # not required\n",
    "        # returns the last prediction and the hidden state\n",
    "        y_hat, h, c = self(x, h, c)\n",
    "        return y_hat[:, -1], h, c # only return the last prediction\n",
    "        \n",
    "    def many_to_many_async(self, x, h, c, steps):\n",
    "        # not required\n",
    "        # combines many-to-one and one-to-many\n",
    "        x_0, h, c = self.many_to_one(x, h, c)\n",
    "        return self.auto_regression(x_0, h, c, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7befc22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the hidden state (True) by activating learning for U_h\n",
    "rnn_mode = True\n",
    "# learn a better initial hidden state representation (True) than zero init\n",
    "learn_h0 = True\n",
    "\n",
    "# number of weight update iterations\n",
    "n_iterations = 25 #250\n",
    "\n",
    "# number of neurons m in the hidden layer\n",
    "num_neurons = 256\n",
    "batch_size  = 1024 #should be 1024\n",
    "lr = 0.01\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c872394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = LSTM(\n",
    "    dims, num_neurons, \n",
    "    learn_h0=learn_h0, \n",
    "    rnn_mode=rnn_mode\n",
    ")\n",
    "rnn.to(device)\n",
    "\n",
    "# standard optimizer SGD or AdaGrad would also work\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ee1f6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5181.453125\n",
      "tensor([[-1.4667e-05, -2.0047e-04,  1.7706e-04,  ...,  3.4106e-04,\n",
      "          1.2953e-03,  4.7017e-04],\n",
      "        [-1.4672e-05, -2.0049e-04,  1.7697e-04,  ...,  3.4101e-04,\n",
      "          1.2952e-03,  4.7008e-04],\n",
      "        [-1.4652e-05, -2.0062e-04,  1.7708e-04,  ...,  3.4107e-04,\n",
      "          1.2954e-03,  4.7034e-04],\n",
      "        ...,\n",
      "        [-1.3276e-05, -2.0094e-04,  1.7662e-04,  ...,  3.4115e-04,\n",
      "          1.2981e-03,  4.7479e-04],\n",
      "        [-1.3210e-05, -2.0087e-04,  1.7664e-04,  ...,  3.4117e-04,\n",
      "          1.2983e-03,  4.7485e-04],\n",
      "        [-1.3163e-05, -2.0078e-04,  1.7655e-04,  ...,  3.4113e-04,\n",
      "          1.2982e-03,  4.7487e-04]])\n",
      "22934.837890625\n",
      "tensor([[-3.2196e-05, -9.4095e-06, -1.1622e-03,  ...,  2.6251e-04,\n",
      "          7.7918e-04, -1.3477e-04],\n",
      "        [-3.2205e-05, -9.4168e-06, -1.1620e-03,  ...,  2.6253e-04,\n",
      "          7.7915e-04, -1.3480e-04],\n",
      "        [-3.2179e-05, -9.3867e-06, -1.1617e-03,  ...,  2.6250e-04,\n",
      "          7.7927e-04, -1.3475e-04],\n",
      "        ...,\n",
      "        [-3.1372e-05, -8.1771e-06, -1.1616e-03,  ...,  2.6503e-04,\n",
      "          7.8933e-04, -1.3595e-04],\n",
      "        [-3.1347e-05, -8.1543e-06, -1.1613e-03,  ...,  2.6504e-04,\n",
      "          7.8932e-04, -1.3592e-04],\n",
      "        [-3.1345e-05, -8.1528e-06, -1.1613e-03,  ...,  2.6513e-04,\n",
      "          7.8952e-04, -1.3598e-04]])\n",
      "12714.2197265625\n",
      "tensor([[ 9.7972e-06,  1.8783e-05,  4.1401e-04,  ..., -1.9789e-04,\n",
      "         -6.9184e-04,  1.4581e-04],\n",
      "        [ 9.8010e-06,  1.8773e-05,  4.1392e-04,  ..., -1.9780e-04,\n",
      "         -6.9155e-04,  1.4577e-04],\n",
      "        [ 9.8105e-06,  1.8820e-05,  4.1385e-04,  ..., -1.9771e-04,\n",
      "         -6.9109e-04,  1.4576e-04],\n",
      "        ...,\n",
      "        [ 1.0094e-05,  2.0533e-05,  4.0216e-04,  ..., -1.9053e-04,\n",
      "         -6.6404e-04,  1.4317e-04],\n",
      "        [ 1.0103e-05,  2.0575e-05,  4.0196e-04,  ..., -1.9041e-04,\n",
      "         -6.6352e-04,  1.4315e-04],\n",
      "        [ 1.0102e-05,  2.0590e-05,  4.0184e-04,  ..., -1.9038e-04,\n",
      "         -6.6344e-04,  1.4309e-04]])\n",
      "5087.6513671875\n",
      "tensor([[ 1.2247e-05,  1.3523e-05,  2.2275e-04,  ..., -2.2089e-04,\n",
      "         -4.3036e-04, -2.4957e-05],\n",
      "        [ 1.2242e-05,  1.3562e-05,  2.2272e-04,  ..., -2.2077e-04,\n",
      "         -4.3007e-04, -2.5015e-05],\n",
      "        [ 1.2251e-05,  1.3612e-05,  2.2271e-04,  ..., -2.2069e-04,\n",
      "         -4.2957e-04, -2.5022e-05],\n",
      "        ...,\n",
      "        [ 1.2285e-05,  1.5540e-05,  2.1561e-04,  ..., -2.1395e-04,\n",
      "         -4.0730e-04, -2.7506e-05],\n",
      "        [ 1.2291e-05,  1.5536e-05,  2.1554e-04,  ..., -2.1394e-04,\n",
      "         -4.0710e-04, -2.7512e-05],\n",
      "        [ 1.2292e-05,  1.5593e-05,  2.1545e-04,  ..., -2.1382e-04,\n",
      "         -4.0682e-04, -2.7573e-05]])\n",
      "17420.552734375\n",
      "tensor([[ 4.9126e-06,  8.2126e-05, -5.9298e-05,  ..., -1.7046e-04,\n",
      "          1.5017e-04, -2.9048e-04],\n",
      "        [ 4.9110e-06,  8.2136e-05, -5.9270e-05,  ..., -1.7042e-04,\n",
      "          1.5020e-04, -2.9054e-04],\n",
      "        [ 4.9163e-06,  8.2167e-05, -5.9257e-05,  ..., -1.7042e-04,\n",
      "          1.5048e-04, -2.9052e-04],\n",
      "        ...,\n",
      "        [ 4.8730e-06,  8.4311e-05, -6.1308e-05,  ..., -1.6507e-04,\n",
      "          1.6598e-04, -2.9254e-04],\n",
      "        [ 4.8742e-06,  8.4321e-05, -6.1359e-05,  ..., -1.6500e-04,\n",
      "          1.6626e-04, -2.9252e-04],\n",
      "        [ 4.8725e-06,  8.4387e-05, -6.1331e-05,  ..., -1.6493e-04,\n",
      "          1.6637e-04, -2.9253e-04]])\n",
      "5365.49169921875\n",
      "tensor([[ 3.7262e-06,  7.4906e-06, -8.0767e-05,  ...,  5.7085e-05,\n",
      "          2.0353e-04, -7.8795e-05],\n",
      "        [ 3.7258e-06,  7.4982e-06, -8.0738e-05,  ...,  5.7075e-05,\n",
      "          2.0351e-04, -7.8821e-05],\n",
      "        [ 3.7308e-06,  7.5171e-06, -8.0718e-05,  ...,  5.7112e-05,\n",
      "          2.0375e-04, -7.8796e-05],\n",
      "        ...,\n",
      "        [ 3.6738e-06,  8.6216e-06, -8.1143e-05,  ...,  6.0523e-05,\n",
      "          2.1555e-04, -8.0077e-05],\n",
      "        [ 3.6724e-06,  8.6280e-06, -8.1176e-05,  ...,  6.0616e-05,\n",
      "          2.1573e-04, -8.0089e-05],\n",
      "        [ 3.6681e-06,  8.6567e-06, -8.1112e-05,  ...,  6.0709e-05,\n",
      "          2.1591e-04, -8.0100e-05]])\n",
      "5163.38916015625\n",
      "tensor([[ 2.2627e-06,  6.8350e-06, -6.0802e-05,  ...,  5.7799e-05,\n",
      "          3.8672e-05, -7.6106e-06],\n",
      "        [ 2.2656e-06,  6.8369e-06, -6.0773e-05,  ...,  5.7791e-05,\n",
      "          3.8629e-05, -7.6199e-06],\n",
      "        [ 2.2715e-06,  6.8475e-06, -6.0755e-05,  ...,  5.7846e-05,\n",
      "          3.8834e-05, -7.6149e-06],\n",
      "        ...,\n",
      "        [ 2.2748e-06,  7.4549e-06, -6.0550e-05,  ...,  6.0489e-05,\n",
      "          4.8276e-05, -8.2812e-06],\n",
      "        [ 2.2765e-06,  7.4661e-06, -6.0548e-05,  ...,  6.0608e-05,\n",
      "          4.8494e-05, -8.2891e-06],\n",
      "        [ 2.2769e-06,  7.4861e-06, -6.0550e-05,  ...,  6.0576e-05,\n",
      "          4.8550e-05, -8.3052e-06]])\n",
      "4926.00537109375\n",
      "tensor([[-7.8593e-07,  2.1911e-05,  5.1721e-06,  ...,  2.2428e-05,\n",
      "         -1.0114e-05,  1.4814e-06],\n",
      "        [-7.8056e-07,  2.1917e-05,  5.1958e-06,  ...,  2.2351e-05,\n",
      "         -1.0150e-05,  1.4732e-06],\n",
      "        [-7.7945e-07,  2.1919e-05,  5.2379e-06,  ...,  2.2496e-05,\n",
      "         -1.0026e-05,  1.4765e-06],\n",
      "        ...,\n",
      "        [-6.0999e-07,  2.2438e-05,  5.5217e-06,  ...,  2.4911e-05,\n",
      "         -2.7981e-06,  1.0951e-06],\n",
      "        [-6.0827e-07,  2.2447e-05,  5.5323e-06,  ...,  2.5011e-05,\n",
      "         -2.6663e-06,  1.0909e-06],\n",
      "        [-6.1628e-07,  2.2451e-05,  5.5271e-06,  ...,  2.4957e-05,\n",
      "         -2.6796e-06,  1.0768e-06]])\n",
      "4494.74853515625\n",
      "tensor([[-2.3875e-06,  2.8319e-05,  4.4982e-05,  ...,  3.5737e-05,\n",
      "         -7.3574e-05,  2.0549e-06],\n",
      "        [-2.3791e-06,  2.8324e-05,  4.5003e-05,  ...,  3.5567e-05,\n",
      "         -7.3538e-05,  2.0466e-06],\n",
      "        [-2.3707e-06,  2.8344e-05,  4.5061e-05,  ...,  3.5747e-05,\n",
      "         -7.3396e-05,  2.0515e-06],\n",
      "        ...,\n",
      "        [-2.0997e-06,  2.8716e-05,  4.5387e-05,  ...,  3.7758e-05,\n",
      "         -6.7821e-05,  1.7375e-06],\n",
      "        [-2.0995e-06,  2.8712e-05,  4.5395e-05,  ...,  3.7882e-05,\n",
      "         -6.7717e-05,  1.7345e-06],\n",
      "        [-2.0921e-06,  2.8745e-05,  4.5420e-05,  ...,  3.7931e-05,\n",
      "         -6.7648e-05,  1.7265e-06]])\n",
      "4732.416015625\n",
      "tensor([[-2.0955e-06,  1.5956e-05,  4.3653e-05,  ..., -5.2496e-06,\n",
      "         -1.3066e-04,  2.6197e-06],\n",
      "        [-2.0925e-06,  1.5964e-05,  4.3666e-05,  ..., -5.3995e-06,\n",
      "         -1.3060e-04,  2.6172e-06],\n",
      "        [-2.0894e-06,  1.5952e-05,  4.3700e-05,  ..., -5.1936e-06,\n",
      "         -1.3054e-04,  2.6164e-06],\n",
      "        ...,\n",
      "        [-1.9288e-06,  1.6076e-05,  4.4063e-05,  ..., -3.6327e-06,\n",
      "         -1.2607e-04,  2.3469e-06],\n",
      "        [-1.9165e-06,  1.6088e-05,  4.4089e-05,  ..., -3.5845e-06,\n",
      "         -1.2596e-04,  2.3475e-06],\n",
      "        [-1.9168e-06,  1.6087e-05,  4.4095e-05,  ..., -3.6023e-06,\n",
      "         -1.2586e-04,  2.3428e-06]])\n",
      "4526.64306640625\n",
      "tensor([[-7.2180e-07,  2.4958e-06,  3.1285e-05,  ...,  2.2398e-05,\n",
      "         -1.0114e-04,  1.2224e-06],\n",
      "        [-7.1391e-07,  2.4946e-06,  3.1291e-05,  ...,  2.2191e-05,\n",
      "         -1.0109e-04,  1.2203e-06],\n",
      "        [-7.1089e-07,  2.4943e-06,  3.1341e-05,  ...,  2.2343e-05,\n",
      "         -1.0115e-04,  1.2212e-06],\n",
      "        ...,\n",
      "        [-5.6547e-07,  2.5438e-06,  3.1800e-05,  ...,  2.3496e-05,\n",
      "         -9.8288e-05,  1.0118e-06],\n",
      "        [-5.6155e-07,  2.5487e-06,  3.1809e-05,  ...,  2.3467e-05,\n",
      "         -9.8269e-05,  1.0122e-06],\n",
      "        [-5.6264e-07,  2.5537e-06,  3.1817e-05,  ...,  2.3529e-05,\n",
      "         -9.8149e-05,  1.0057e-06]])\n",
      "4768.46435546875\n",
      "tensor([[ 2.8426e-07, -1.7529e-06,  1.1933e-05,  ...,  2.4318e-05,\n",
      "         -5.2293e-05,  3.6522e-08],\n",
      "        [ 2.8884e-07, -1.7516e-06,  1.1938e-05,  ...,  2.4287e-05,\n",
      "         -5.2330e-05,  3.5075e-08],\n",
      "        [ 2.9258e-07, -1.7494e-06,  1.1964e-05,  ...,  2.4368e-05,\n",
      "         -5.2283e-05,  3.4733e-08],\n",
      "        ...,\n",
      "        [ 4.7315e-07, -1.6868e-06,  1.2409e-05,  ...,  2.5027e-05,\n",
      "         -5.0862e-05, -1.1170e-07],\n",
      "        [ 4.7509e-07, -1.6825e-06,  1.2419e-05,  ...,  2.5094e-05,\n",
      "         -5.0812e-05, -1.1247e-07],\n",
      "        [ 4.7185e-07, -1.6827e-06,  1.2428e-05,  ...,  2.5022e-05,\n",
      "         -5.0860e-05, -1.1859e-07]])\n",
      "4451.48388671875\n",
      "tensor([[ 1.4258e-06, -1.8962e-06,  4.2201e-08,  ..., -5.6035e-05,\n",
      "         -3.1024e-05, -1.0837e-07],\n",
      "        [ 1.4278e-06, -1.8982e-06,  4.0196e-08,  ..., -5.6118e-05,\n",
      "         -3.1143e-05, -1.1237e-07],\n",
      "        [ 1.4355e-06, -1.8968e-06,  6.2981e-08,  ..., -5.6030e-05,\n",
      "         -3.1093e-05, -1.0914e-07],\n",
      "        ...,\n",
      "        [ 1.6165e-06, -1.8523e-06,  4.1588e-07,  ..., -5.5619e-05,\n",
      "         -2.9855e-05, -2.3424e-07],\n",
      "        [ 1.6187e-06, -1.8456e-06,  4.1553e-07,  ..., -5.5670e-05,\n",
      "         -2.9826e-05, -2.3332e-07],\n",
      "        [ 1.6223e-06, -1.8459e-06,  4.1533e-07,  ..., -5.5646e-05,\n",
      "         -2.9782e-05, -2.3796e-07]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4853.216796875\n",
      "tensor([[ 2.2407e-06, -1.1990e-06, -6.8054e-06,  ..., -9.3038e-05,\n",
      "         -4.9386e-06, -1.9673e-07],\n",
      "        [ 2.2459e-06, -1.1964e-06, -6.8075e-06,  ..., -9.3159e-05,\n",
      "         -5.0371e-06, -1.9869e-07],\n",
      "        [ 2.2528e-06, -1.1993e-06, -6.7948e-06,  ..., -9.3061e-05,\n",
      "         -5.0039e-06, -1.9734e-07],\n",
      "        ...,\n",
      "        [ 2.4567e-06, -1.1497e-06, -6.5046e-06,  ..., -9.2779e-05,\n",
      "         -3.7946e-06, -2.9364e-07],\n",
      "        [ 2.4543e-06, -1.1492e-06, -6.4976e-06,  ..., -9.2733e-05,\n",
      "         -3.7322e-06, -2.9762e-07],\n",
      "        [ 2.4573e-06, -1.1494e-06, -6.4982e-06,  ..., -9.2718e-05,\n",
      "         -3.7371e-06, -2.9918e-07]])\n",
      "4457.904296875\n",
      "tensor([[ 2.4432e-06,  7.2040e-08, -1.3864e-05,  ..., -3.6210e-05,\n",
      "          3.3344e-05, -6.3955e-07],\n",
      "        [ 2.4482e-06,  7.2767e-08, -1.3871e-05,  ..., -3.6249e-05,\n",
      "          3.3299e-05, -6.4118e-07],\n",
      "        [ 2.4547e-06,  7.1656e-08, -1.3849e-05,  ..., -3.6248e-05,\n",
      "          3.3255e-05, -6.3973e-07],\n",
      "        ...,\n",
      "        [ 2.6813e-06,  1.3049e-07, -1.3645e-05,  ..., -3.5739e-05,\n",
      "          3.4196e-05, -7.2301e-07],\n",
      "        [ 2.6807e-06,  1.3167e-07, -1.3650e-05,  ..., -3.5707e-05,\n",
      "          3.4276e-05, -7.2461e-07],\n",
      "        [ 2.6824e-06,  1.3107e-07, -1.3642e-05,  ..., -3.5748e-05,\n",
      "          3.4236e-05, -7.2716e-07]])\n",
      "4717.16943359375\n",
      "tensor([[ 2.5268e-06,  7.6718e-07, -1.7225e-05,  ..., -5.0142e-06,\n",
      "          5.4870e-05, -6.9186e-07],\n",
      "        [ 2.5336e-06,  7.6715e-07, -1.7227e-05,  ..., -5.0351e-06,\n",
      "          5.4767e-05, -6.9390e-07],\n",
      "        [ 2.5423e-06,  7.6764e-07, -1.7215e-05,  ..., -5.0411e-06,\n",
      "          5.4821e-05, -6.9233e-07],\n",
      "        ...,\n",
      "        [ 2.7785e-06,  8.3087e-07, -1.7044e-05,  ..., -4.4498e-06,\n",
      "          5.5830e-05, -7.6711e-07],\n",
      "        [ 2.7793e-06,  8.3138e-07, -1.7040e-05,  ..., -4.3814e-06,\n",
      "          5.5938e-05, -7.6802e-07],\n",
      "        [ 2.7832e-06,  8.3241e-07, -1.7039e-05,  ..., -4.4086e-06,\n",
      "          5.5914e-05, -7.7044e-07]])\n",
      "4466.1513671875\n",
      "tensor([[ 2.8085e-06,  1.0053e-06, -1.7135e-05,  ..., -1.9596e-05,\n",
      "          3.9943e-05, -6.0709e-07],\n",
      "        [ 2.8123e-06,  1.0052e-06, -1.7141e-05,  ..., -1.9678e-05,\n",
      "          3.9820e-05, -6.0825e-07],\n",
      "        [ 2.8203e-06,  1.0048e-06, -1.7136e-05,  ..., -1.9648e-05,\n",
      "          3.9847e-05, -6.0620e-07],\n",
      "        ...,\n",
      "        [ 3.0726e-06,  1.0681e-06, -1.6985e-05,  ..., -1.9121e-05,\n",
      "          4.1353e-05, -6.7762e-07],\n",
      "        [ 3.0766e-06,  1.0704e-06, -1.6986e-05,  ..., -1.9072e-05,\n",
      "          4.1488e-05, -6.7861e-07],\n",
      "        [ 3.0798e-06,  1.0706e-06, -1.6981e-05,  ..., -1.9078e-05,\n",
      "          4.1484e-05, -6.8121e-07]])\n",
      "4726.474609375\n",
      "tensor([[ 3.4385e-06,  1.2914e-06, -1.4054e-05,  ..., -3.6082e-05,\n",
      "          2.8686e-06, -4.3112e-07],\n",
      "        [ 3.4433e-06,  1.2924e-06, -1.4057e-05,  ..., -3.6110e-05,\n",
      "          2.8173e-06, -4.3267e-07],\n",
      "        [ 3.4528e-06,  1.2918e-06, -1.4044e-05,  ..., -3.6129e-05,\n",
      "          2.7762e-06, -4.3197e-07],\n",
      "        ...,\n",
      "        [ 3.7265e-06,  1.3569e-06, -1.3900e-05,  ..., -3.5735e-05,\n",
      "          4.6771e-06, -4.9577e-07],\n",
      "        [ 3.7309e-06,  1.3591e-06, -1.3900e-05,  ..., -3.5654e-05,\n",
      "          4.7497e-06, -4.9632e-07],\n",
      "        [ 3.7318e-06,  1.3595e-06, -1.3890e-05,  ..., -3.5702e-05,\n",
      "          4.7442e-06, -4.9917e-07]])\n",
      "4460.6396484375\n",
      "tensor([[ 3.8459e-06,  1.6008e-06, -9.7151e-06,  ..., -3.9764e-05,\n",
      "         -3.5697e-05, -2.5704e-07],\n",
      "        [ 3.8515e-06,  1.6019e-06, -9.7199e-06,  ..., -3.9879e-05,\n",
      "         -3.5813e-05, -2.5904e-07],\n",
      "        [ 3.8608e-06,  1.6009e-06, -9.7114e-06,  ..., -3.9798e-05,\n",
      "         -3.5785e-05, -2.5750e-07],\n",
      "        ...,\n",
      "        [ 4.1590e-06,  1.6712e-06, -9.5788e-06,  ..., -3.9577e-05,\n",
      "         -3.3695e-05, -3.1604e-07],\n",
      "        [ 4.1660e-06,  1.6731e-06, -9.5749e-06,  ..., -3.9504e-05,\n",
      "         -3.3567e-05, -3.1593e-07],\n",
      "        [ 4.1683e-06,  1.6736e-06, -9.5723e-06,  ..., -3.9524e-05,\n",
      "         -3.3562e-05, -3.1893e-07]])\n",
      "4688.64599609375\n",
      "tensor([[ 2.9508e-06,  1.7988e-06, -4.8491e-06,  ..., -2.3918e-05,\n",
      "         -5.8561e-05, -1.4505e-07],\n",
      "        [ 2.9577e-06,  1.8007e-06, -4.8476e-06,  ..., -2.3990e-05,\n",
      "         -5.8721e-05, -1.4667e-07],\n",
      "        [ 2.9701e-06,  1.8005e-06, -4.8344e-06,  ..., -2.3936e-05,\n",
      "         -5.8681e-05, -1.4560e-07],\n",
      "        ...,\n",
      "        [ 3.2900e-06,  1.8720e-06, -4.6931e-06,  ..., -2.3582e-05,\n",
      "         -5.6292e-05, -1.9829e-07],\n",
      "        [ 3.2939e-06,  1.8744e-06, -4.7003e-06,  ..., -2.3573e-05,\n",
      "         -5.6206e-05, -1.9937e-07],\n",
      "        [ 3.2948e-06,  1.8742e-06, -4.6941e-06,  ..., -2.3592e-05,\n",
      "         -5.6235e-05, -2.0215e-07]])\n",
      "4455.3427734375\n",
      "tensor([[-6.3795e-07,  1.9529e-06, -4.7024e-07,  ...,  1.2452e-05,\n",
      "         -4.7268e-05, -1.4938e-07],\n",
      "        [-6.2994e-07,  1.9549e-06, -4.6977e-07,  ...,  1.2409e-05,\n",
      "         -4.7392e-05, -1.5063e-07],\n",
      "        [-6.2051e-07,  1.9550e-06, -4.6105e-07,  ...,  1.2349e-05,\n",
      "         -4.7375e-05, -1.5018e-07],\n",
      "        ...,\n",
      "        [-2.9509e-07,  2.0316e-06, -3.3217e-07,  ...,  1.2801e-05,\n",
      "         -4.5035e-05, -2.0282e-07],\n",
      "        [-2.8975e-07,  2.0335e-06, -3.2679e-07,  ...,  1.2848e-05,\n",
      "         -4.4896e-05, -2.0250e-07],\n",
      "        [-2.9443e-07,  2.0324e-06, -3.1860e-07,  ...,  1.2817e-05,\n",
      "         -4.4939e-05, -2.0495e-07]])\n",
      "5002.0576171875\n",
      "tensor([[-6.8112e-06,  2.0328e-06,  2.6306e-06,  ...,  5.5384e-05,\n",
      "         -9.5359e-06, -2.1014e-07],\n",
      "        [-6.8074e-06,  2.0345e-06,  2.6338e-06,  ...,  5.5378e-05,\n",
      "         -9.6884e-06, -2.1197e-07],\n",
      "        [-6.7923e-06,  2.0331e-06,  2.6462e-06,  ...,  5.5381e-05,\n",
      "         -9.6290e-06, -2.0981e-07],\n",
      "        ...,\n",
      "        [-6.4606e-06,  2.1206e-06,  2.7605e-06,  ...,  5.5810e-05,\n",
      "         -7.3830e-06, -2.6372e-07],\n",
      "        [-6.4570e-06,  2.1207e-06,  2.7641e-06,  ...,  5.5887e-05,\n",
      "         -7.2550e-06, -2.6351e-07],\n",
      "        [-6.4570e-06,  2.1222e-06,  2.7682e-06,  ...,  5.5898e-05,\n",
      "         -7.3132e-06, -2.6556e-07]])\n",
      "4456.95654296875\n",
      "tensor([[-1.2058e-05,  1.6167e-06,  4.9148e-06,  ...,  7.5685e-05,\n",
      "          1.9083e-05, -2.0434e-07],\n",
      "        [-1.2053e-05,  1.6173e-06,  4.9174e-06,  ...,  7.5698e-05,\n",
      "          1.8994e-05, -2.0542e-07],\n",
      "        [-1.2039e-05,  1.6165e-06,  4.9319e-06,  ...,  7.5717e-05,\n",
      "          1.9055e-05, -2.0376e-07],\n",
      "        ...,\n",
      "        [-1.1712e-05,  1.7080e-06,  5.0365e-06,  ...,  7.6119e-05,\n",
      "          2.1282e-05, -2.5735e-07],\n",
      "        [-1.1703e-05,  1.7096e-06,  5.0393e-06,  ...,  7.6242e-05,\n",
      "          2.1470e-05, -2.5718e-07],\n",
      "        [-1.1706e-05,  1.7102e-06,  5.0418e-06,  ...,  7.6197e-05,\n",
      "          2.1401e-05, -2.6010e-07]])\n",
      "4711.96484375\n",
      "tensor([[-1.2339e-05,  5.2689e-07,  6.2597e-06,  ...,  6.3188e-05,\n",
      "          1.5871e-05, -9.2321e-08],\n",
      "        [-1.2339e-05,  5.2765e-07,  6.2616e-06,  ...,  6.3105e-05,\n",
      "          1.5735e-05, -9.3062e-08],\n",
      "        [-1.2321e-05,  5.2609e-07,  6.2791e-06,  ...,  6.3184e-05,\n",
      "          1.5791e-05, -9.2147e-08],\n",
      "        ...,\n",
      "        [-1.2004e-05,  6.1636e-07,  6.3783e-06,  ...,  6.3562e-05,\n",
      "          1.8331e-05, -1.4416e-07],\n",
      "        [-1.1999e-05,  6.1774e-07,  6.3829e-06,  ...,  6.3627e-05,\n",
      "          1.8450e-05, -1.4483e-07],\n",
      "        [-1.2001e-05,  6.1948e-07,  6.3821e-06,  ...,  6.3642e-05,\n",
      "          1.8424e-05, -1.4705e-07]])\n",
      "4439.490234375\n",
      "tensor([[-8.4626e-06, -6.2421e-07,  5.1800e-06,  ...,  2.7657e-05,\n",
      "         -6.2290e-06,  4.3502e-08],\n",
      "        [-8.4566e-06, -6.2280e-07,  5.1831e-06,  ...,  2.7612e-05,\n",
      "         -6.3241e-06,  4.2574e-08],\n",
      "        [-8.4432e-06, -6.2535e-07,  5.1942e-06,  ...,  2.7597e-05,\n",
      "         -6.3117e-06,  4.3799e-08],\n",
      "        ...,\n",
      "        [-8.1441e-06, -5.4062e-07,  5.3004e-06,  ...,  2.7961e-05,\n",
      "         -3.5667e-06, -6.7127e-09],\n",
      "        [-8.1364e-06, -5.3876e-07,  5.3062e-06,  ...,  2.8081e-05,\n",
      "         -3.3425e-06, -6.5104e-09],\n",
      "        [-8.1388e-06, -5.3651e-07,  5.3037e-06,  ...,  2.8031e-05,\n",
      "         -3.4671e-06, -9.1714e-09]])\n"
     ]
    }
   ],
   "source": [
    "rnn.train()\n",
    "iteration = 0\n",
    "# how often we plot the prediction\n",
    "log_iter = 10\n",
    "iter_loss = []\n",
    "\n",
    "# train for a set number of iterations\n",
    "for iteration in range(n_iterations):\n",
    "\n",
    "    # generates a long time series / normally loaded from dataset (e.g. stocks, weather)\n",
    "    x, y = generateData(\n",
    "        dims, signal_length, predict_ahead, signal_repeats, batch_size, noise_strength\n",
    "    )\n",
    "\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    h = c = None\n",
    "    # reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "#    t0 = time.time()\n",
    "    start.record()\n",
    "\n",
    "    # get predictions (forward pass)\n",
    "    y_hat, h, c = rnn(x, h, c)\n",
    "           \n",
    "    # calculate mean squared error\n",
    "    loss = torch.mean((y_hat - y)**2)        \n",
    "    # backprop\n",
    "    loss.backward()\n",
    "\n",
    "    end.record()\n",
    "#    torch.cuda.current_stream().synchronize()\n",
    "#    t1 = time.time()\n",
    "#    print(t1-t0)\n",
    "\n",
    "    # Waits for everything to finish running\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    print(start.elapsed_time(end))\n",
    "\n",
    "    print(rnn.W_o.grad)\n",
    "    # finally we are adapting the weights with the saved gradient information\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    # log loss\n",
    "#    iter_loss.append(loss.item())\n",
    "    \n",
    "    # plot model predictions during training\n",
    "#    if iteration % log_iter == 0:\n",
    "#        replot(x[0].cpu(), y_hat[0].detach().cpu(), \n",
    "#               y[0].cpu(), iteration + 1, iter_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57763251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db6482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
