{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49fe545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a362ac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension of input\n",
    "dims = 80\n",
    "\n",
    "signal_length = 100\n",
    "signal_repeats = 3\n",
    "predict_ahead = 1\n",
    "noise_strength = 0.03\n",
    "total_series_length = signal_length * signal_repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c823759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData(dims, signal_length, predict_ahead, \n",
    "                 signal_repeats, batch_size, noise_strength):\n",
    "    total_series_length = signal_length * signal_repeats\n",
    "    time = np.linspace(\n",
    "        0, np.pi*2*signal_repeats, \n",
    "        total_series_length * dims + predict_ahead * dims, dtype=np.float32\n",
    "    )\n",
    "    time = time.reshape((1, -1, dims))  \n",
    "    \n",
    "    # include shift for batches\n",
    "    time = np.repeat(time, batch_size, 0)\n",
    "    time += np.random.random(batch_size)[:, None, None] * 10\n",
    "    y = np.sin(time)\n",
    "    input_ = y[:, :total_series_length, :].copy()\n",
    "    if noise_strength > 0:\n",
    "        input_ += np.random.normal(size=(input_.shape)) * noise_strength # add some noise to the input\n",
    "    target = y[:, predict_ahead:, :]\n",
    "    return torch.tensor(input_) , torch.tensor(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88453724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, define our model and initialize the learnable weights and biases (parameters):\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, dims, hidden_dims,\n",
    "                 learn_h0=False, learn_c0=False,\n",
    "                 activation_h=nn.Tanh,\n",
    "                 activation_o=nn.Sigmoid, activation_f=nn.Tanh, \n",
    "                 activation_i=nn.Sigmoid, activation_j=nn.Sigmoid, \n",
    "                 rnn_mode=True):\n",
    "        super().__init__()\n",
    "        # it is fine to hard code these \n",
    "        self.activation_h = activation_h()\n",
    "        self.activation_o = activation_o()\n",
    "        self.activation_f = activation_f()\n",
    "        self.activation_i = activation_i()\n",
    "        self.activation_j = activation_j()\n",
    "        \n",
    "        # parameters of the (recurrent) hidden layer\n",
    "        self.W_o = nn.Parameter(torch.randn(dims, hidden_dims) * .1)\n",
    "        self.b_o = nn.Parameter(torch.zeros(1, hidden_dims))\n",
    "        self.W_f = nn.Parameter(torch.randn(dims, hidden_dims) * .1)\n",
    "        self.b_f = nn.Parameter(torch.zeros(1, hidden_dims))\n",
    "        self.W_i = nn.Parameter(torch.randn(dims, hidden_dims) * .1)\n",
    "        self.b_i = nn.Parameter(torch.zeros(1, hidden_dims))\n",
    "        self.W_j = nn.Parameter(torch.randn(dims, hidden_dims) * .1)\n",
    "        self.b_j = nn.Parameter(torch.zeros(1, hidden_dims))\n",
    "        \n",
    "        \n",
    "        self.U_o = nn.Parameter(\n",
    "            torch.randn(hidden_dims, hidden_dims) * .1\n",
    "        )\n",
    "        self.U_f = nn.Parameter(\n",
    "            torch.randn(hidden_dims, hidden_dims) * .1\n",
    "        )\n",
    "        self.U_i = nn.Parameter(\n",
    "            torch.randn(hidden_dims, hidden_dims) * .1\n",
    "        )\n",
    "        self.U_j = nn.Parameter(\n",
    "            torch.randn(hidden_dims, hidden_dims) * .1\n",
    "        )\n",
    "        \n",
    "        if not rnn_mode:\n",
    "            self.U_o.zero_(); self.U_f.zero_(); self.U_i.zero_(); self.U_j.zero_()\n",
    "            self.U_o.requires_grad = False\n",
    "            self.U_f.requires_grad = False\n",
    "            self.U_i.requires_grad = False\n",
    "            self.U_j.requires_grad = False\n",
    "\n",
    "        # initial hidden state\n",
    "        self.h_0 = nn.Parameter(\n",
    "            torch.zeros(1, hidden_dims),\n",
    "            requires_grad=learn_h0 # only train this if enabled\n",
    "        )        \n",
    "        \n",
    "        # initial cell state\n",
    "        self.c_0 = nn.Parameter(\n",
    "            torch.zeros(1, hidden_dims),\n",
    "            requires_grad=learn_c0 # only train this if enabled\n",
    "        )\n",
    "        \n",
    "        # output layer (fully connected)\n",
    "        self.W_y = nn.Parameter(torch.randn(hidden_dims, dims) * .1)\n",
    "        self.b_y = nn.Parameter(torch.zeros(1, dims))\n",
    "                \n",
    "    def step(self, x_t, h, c):\n",
    "        #  forward pass for a single time step\n",
    "        # hint: a more clever implementation could combine all these and select the different parts later\n",
    "        j = self.activation_j(\n",
    "            torch.matmul(x_t, self.W_j) + torch.matmul(h, self.U_j) + self.b_j\n",
    "        )\n",
    "        i = self.activation_i(\n",
    "            torch.matmul(x_t, self.W_i) + torch.matmul(h, self.U_i) + self.b_i\n",
    "        )\n",
    "        f = self.activation_f(\n",
    "            torch.matmul(x_t, self.W_f) + torch.matmul(h, self.U_f) + self.b_f\n",
    "        )        \n",
    "        o = self.activation_o(\n",
    "            torch.matmul(x_t, self.W_o) + torch.matmul(h, self.U_o) + self.b_o\n",
    "        )\n",
    "        \n",
    "        \n",
    "        c = f * c + i * j\n",
    "        \n",
    "        h = o * self.activation_h(c)\n",
    "\n",
    "        return h, c # returning new hidden and cell state\n",
    "\n",
    "    def iterate_series(self, x, h, c):\n",
    "        # apply rnn to each time step and give an output (many-to-many task)\n",
    "        batch_size, n_steps, dimensions = x.shape\n",
    "        \n",
    "        # can use cell states list here but only the last cell is required\n",
    "        hidden_states = []\n",
    "        # iterate over time axis (1)\n",
    "        for t in range(n_steps):\n",
    "            # give previous hidden state and input from the current time step\n",
    "            h, c = self.step(x[:, t], h, c)\n",
    "            hidden_states.append(h)\n",
    "        hidden_states = torch.stack(hidden_states, 1)\n",
    "        \n",
    "        # fully connected output\n",
    "        y_hat = hidden_states.reshape(batch_size * n_steps, -1) # flatten steps and batch size (bs * )\n",
    "        y_hat = torch.matmul(y_hat, self.W_y) + self.b_y\n",
    "        y_hat = y_hat.reshape(batch_size, n_steps, -1) # regains structure\n",
    "        return y_hat, hidden_states[:, -1], c\n",
    "    \n",
    "    def forward(self, x, h, c):\n",
    "        # x: b, t, d\n",
    "        batch_size = x.shape[0] \n",
    "        if h is None:\n",
    "            h = self.h_0.repeat_interleave(batch_size, 0)\n",
    "        if c is None:\n",
    "            c = self.c_0.repeat_interleave(batch_size, 0)\n",
    "        y_hat, h, c = self.iterate_series(x, h, c)\n",
    "        return y_hat, h, c\n",
    "    \n",
    "    def auto_regression(self, x_0, h, c, steps):\n",
    "        # one-to-many task (steps = \\delta')\n",
    "        x_prev = x_0\n",
    "        y_hat = []\n",
    "        # iterate over time axis (1)\n",
    "        for t in range(steps):\n",
    "            # give previous hidden state and input from the current time step\n",
    "            h, c = self.step(x_prev, h, c)\n",
    "            # here we need to apply the output layer on each step individually\n",
    "            x_prev = torch.matmul(h, self.W_y) + self.b_y\n",
    "            \n",
    "            y_hat.append(x_prev)\n",
    "        y_hat = torch.stack(y_hat, 1)\n",
    "        return y_hat, h, c\n",
    "    \n",
    "    def many_to_one(self, x, h, c):\n",
    "        # not required\n",
    "        # returns the last prediction and the hidden state\n",
    "        y_hat, h, c = self(x, h, c)\n",
    "        return y_hat[:, -1], h, c # only return the last prediction\n",
    "        \n",
    "    def many_to_many_async(self, x, h, c, steps):\n",
    "        # not required\n",
    "        # combines many-to-one and one-to-many\n",
    "        x_0, h, c = self.many_to_one(x, h, c)\n",
    "        return self.auto_regression(x_0, h, c, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7befc22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the hidden state (True) by activating learning for U_h\n",
    "rnn_mode = True\n",
    "# learn a better initial hidden state representation (True) than zero init\n",
    "learn_h0 = True\n",
    "\n",
    "# number of weight update iterations\n",
    "n_iterations = 25 #250\n",
    "\n",
    "# number of neurons m in the hidden layer\n",
    "num_neurons = 256\n",
    "batch_size  = 1024 #should be 1024\n",
    "lr = 0.01\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c872394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = LSTM(\n",
    "    dims, num_neurons, \n",
    "    learn_h0=learn_h0, \n",
    "    rnn_mode=rnn_mode\n",
    ")\n",
    "rnn.to(device)\n",
    "\n",
    "# standard optimizer SGD or AdaGrad would also work\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ee1f6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267.7424011230469\n",
      "tensor([[ 0.0014, -0.0005, -0.0016,  ...,  0.0018, -0.0004,  0.0005],\n",
      "        [ 0.0014, -0.0005, -0.0016,  ...,  0.0018, -0.0004,  0.0005],\n",
      "        [ 0.0014, -0.0005, -0.0016,  ...,  0.0018, -0.0004,  0.0005],\n",
      "        ...,\n",
      "        [ 0.0014, -0.0005, -0.0016,  ...,  0.0018, -0.0004,  0.0005],\n",
      "        [ 0.0014, -0.0005, -0.0016,  ...,  0.0018, -0.0004,  0.0005],\n",
      "        [ 0.0014, -0.0005, -0.0016,  ...,  0.0018, -0.0004,  0.0005]],\n",
      "       device='cuda:0')\n",
      "231.70684814453125\n",
      "tensor([[-3.4384e-04,  3.0527e-04,  1.2909e-04,  ...,  4.5885e-04,\n",
      "          2.0903e-04,  1.7892e-05],\n",
      "        [-3.4387e-04,  3.0510e-04,  1.2920e-04,  ...,  4.5886e-04,\n",
      "          2.0911e-04,  1.7983e-05],\n",
      "        [-3.4392e-04,  3.0503e-04,  1.2920e-04,  ...,  4.5877e-04,\n",
      "          2.0904e-04,  1.8006e-05],\n",
      "        ...,\n",
      "        [-3.4485e-04,  2.9816e-04,  1.3440e-04,  ...,  4.5764e-04,\n",
      "          2.1051e-04,  2.1856e-05],\n",
      "        [-3.4491e-04,  2.9799e-04,  1.3447e-04,  ...,  4.5754e-04,\n",
      "          2.1047e-04,  2.1907e-05],\n",
      "        [-3.4484e-04,  2.9797e-04,  1.3456e-04,  ...,  4.5756e-04,\n",
      "          2.1058e-04,  2.1946e-05]], device='cuda:0')\n",
      "218.05459594726562\n",
      "tensor([[ 7.6901e-05, -2.1016e-04,  2.1104e-05,  ...,  4.8933e-04,\n",
      "         -5.4114e-05, -5.9954e-04],\n",
      "        [ 7.6889e-05, -2.1016e-04,  2.1124e-05,  ...,  4.8929e-04,\n",
      "         -5.4121e-05, -5.9944e-04],\n",
      "        [ 7.6885e-05, -2.1016e-04,  2.1159e-05,  ...,  4.8936e-04,\n",
      "         -5.4073e-05, -5.9941e-04],\n",
      "        ...,\n",
      "        [ 7.5430e-05, -2.1086e-04,  2.4184e-05,  ...,  4.8659e-04,\n",
      "         -5.1669e-05, -5.9106e-04],\n",
      "        [ 7.5483e-05, -2.1084e-04,  2.4226e-05,  ...,  4.8654e-04,\n",
      "         -5.1647e-05, -5.9089e-04],\n",
      "        [ 7.5401e-05, -2.1084e-04,  2.4259e-05,  ...,  4.8638e-04,\n",
      "         -5.1622e-05, -5.9076e-04]], device='cuda:0')\n",
      "225.13836669921875\n",
      "tensor([[ 2.8960e-05, -1.2005e-04, -5.5549e-05,  ..., -4.5756e-05,\n",
      "         -6.2711e-05, -9.8414e-05],\n",
      "        [ 2.8936e-05, -1.2005e-04, -5.5484e-05,  ..., -4.5806e-05,\n",
      "         -6.2677e-05, -9.8271e-05],\n",
      "        [ 2.8912e-05, -1.2006e-04, -5.5452e-05,  ..., -4.5793e-05,\n",
      "         -6.2649e-05, -9.8206e-05],\n",
      "        ...,\n",
      "        [ 2.7590e-05, -1.2103e-04, -5.3375e-05,  ..., -4.8081e-05,\n",
      "         -6.0604e-05, -9.2651e-05],\n",
      "        [ 2.7585e-05, -1.2104e-04, -5.3310e-05,  ..., -4.8159e-05,\n",
      "         -6.0562e-05, -9.2529e-05],\n",
      "        [ 2.7550e-05, -1.2105e-04, -5.3301e-05,  ..., -4.8110e-05,\n",
      "         -6.0544e-05, -9.2479e-05]], device='cuda:0')\n",
      "234.0884552001953\n",
      "tensor([[ 3.1389e-06,  7.9050e-05, -1.0480e-05,  ..., -4.0028e-04,\n",
      "         -2.3403e-05,  3.2830e-04],\n",
      "        [ 3.1357e-06,  7.9019e-05, -1.0471e-05,  ..., -4.0028e-04,\n",
      "         -2.3399e-05,  3.2835e-04],\n",
      "        [ 3.1030e-06,  7.9042e-05, -1.0458e-05,  ..., -4.0029e-04,\n",
      "         -2.3362e-05,  3.2840e-04],\n",
      "        ...,\n",
      "        [ 1.9267e-06,  7.7721e-05, -8.8253e-06,  ..., -4.0359e-04,\n",
      "         -2.1779e-05,  3.3272e-04],\n",
      "        [ 1.9002e-06,  7.7671e-05, -8.7968e-06,  ..., -4.0354e-04,\n",
      "         -2.1755e-05,  3.3263e-04],\n",
      "        [ 1.8896e-06,  7.7680e-05, -8.7769e-06,  ..., -4.0345e-04,\n",
      "         -2.1737e-05,  3.3278e-04]], device='cuda:0')\n",
      "227.40170288085938\n",
      "tensor([[-1.7839e-05,  2.8923e-04,  7.3475e-06,  ..., -3.1740e-04,\n",
      "          6.4182e-06,  3.0243e-04],\n",
      "        [-1.7847e-05,  2.8917e-04,  7.3837e-06,  ..., -3.1739e-04,\n",
      "          6.4489e-06,  3.0247e-04],\n",
      "        [-1.7864e-05,  2.8923e-04,  7.4050e-06,  ..., -3.1737e-04,\n",
      "          6.4579e-06,  3.0248e-04],\n",
      "        ...,\n",
      "        [-1.9180e-05,  2.8882e-04,  9.9503e-06,  ..., -3.2115e-04,\n",
      "          7.9027e-06,  3.0613e-04],\n",
      "        [-1.9208e-05,  2.8880e-04,  9.9880e-06,  ..., -3.2118e-04,\n",
      "          7.9145e-06,  3.0611e-04],\n",
      "        [-1.9218e-05,  2.8883e-04,  1.0023e-05,  ..., -3.2110e-04,\n",
      "          7.9359e-06,  3.0615e-04]], device='cuda:0')\n",
      "223.5963592529297\n",
      "tensor([[-2.5130e-05,  1.7626e-04,  1.2194e-06,  ..., -1.3567e-04,\n",
      "         -5.0617e-07, -7.0667e-06],\n",
      "        [-2.5158e-05,  1.7622e-04,  1.2268e-06,  ..., -1.3568e-04,\n",
      "         -5.0115e-07, -6.9579e-06],\n",
      "        [-2.5173e-05,  1.7624e-04,  1.2504e-06,  ..., -1.3567e-04,\n",
      "         -4.8729e-07, -6.8771e-06],\n",
      "        ...,\n",
      "        [-2.6589e-05,  1.7625e-04,  2.5902e-06,  ..., -1.3836e-04,\n",
      "          3.8064e-07, -2.9749e-06],\n",
      "        [-2.6653e-05,  1.7615e-04,  2.6172e-06,  ..., -1.3841e-04,\n",
      "          3.8033e-07, -3.0062e-06],\n",
      "        [-2.6666e-05,  1.7623e-04,  2.6316e-06,  ..., -1.3840e-04,\n",
      "          3.9600e-07, -2.9649e-06]], device='cuda:0')\n",
      "218.00096130371094\n",
      "tensor([[-1.1554e-05,  3.5732e-05, -1.5381e-06,  ..., -3.6784e-05,\n",
      "         -3.6522e-06, -2.6991e-04],\n",
      "        [-1.1566e-05,  3.5701e-05, -1.5392e-06,  ..., -3.6804e-05,\n",
      "         -3.6477e-06, -2.6982e-04],\n",
      "        [-1.1581e-05,  3.5734e-05, -1.5202e-06,  ..., -3.6792e-05,\n",
      "         -3.6347e-06, -2.6975e-04],\n",
      "        ...,\n",
      "        [-1.3148e-05,  3.5616e-05, -8.6758e-07,  ..., -3.8604e-05,\n",
      "         -3.0185e-06, -2.6501e-04],\n",
      "        [-1.3187e-05,  3.5612e-05, -8.3352e-07,  ..., -3.8663e-05,\n",
      "         -2.9986e-06, -2.6482e-04],\n",
      "        [-1.3212e-05,  3.5631e-05, -8.3753e-07,  ..., -3.8645e-05,\n",
      "         -2.9974e-06, -2.6490e-04]], device='cuda:0')\n",
      "217.95779418945312\n",
      "tensor([[-2.3145e-05, -3.3303e-05, -1.2666e-07,  ..., -1.7556e-06,\n",
      "         -1.7811e-06, -1.4951e-04],\n",
      "        [-2.3169e-05, -3.3307e-05, -1.2225e-07,  ..., -1.7622e-06,\n",
      "         -1.7816e-06, -1.4936e-04],\n",
      "        [-2.3200e-05, -3.3295e-05, -1.0946e-07,  ..., -1.7674e-06,\n",
      "         -1.7645e-06, -1.4933e-04],\n",
      "        ...,\n",
      "        [-2.4804e-05, -3.3491e-05,  4.1266e-07,  ..., -3.0622e-06,\n",
      "         -1.2831e-06, -1.4507e-04],\n",
      "        [-2.4829e-05, -3.3514e-05,  4.3441e-07,  ..., -3.0919e-06,\n",
      "         -1.2687e-06, -1.4499e-04],\n",
      "        [-2.4849e-05, -3.3505e-05,  4.3484e-07,  ..., -3.0827e-06,\n",
      "         -1.2673e-06, -1.4506e-04]], device='cuda:0')\n",
      "218.85638427734375\n",
      "tensor([[-1.3919e-05, -4.9809e-05,  2.6419e-07,  ...,  3.1273e-05,\n",
      "         -1.1958e-06,  4.3326e-05],\n",
      "        [-1.3934e-05, -4.9812e-05,  2.7080e-07,  ...,  3.1261e-05,\n",
      "         -1.1927e-06,  4.3508e-05],\n",
      "        [-1.3958e-05, -4.9780e-05,  2.7518e-07,  ...,  3.1288e-05,\n",
      "         -1.1878e-06,  4.3492e-05],\n",
      "        ...,\n",
      "        [-1.5242e-05, -5.0094e-05,  6.8293e-07,  ...,  3.0152e-05,\n",
      "         -8.5687e-07,  4.6862e-05],\n",
      "        [-1.5261e-05, -5.0096e-05,  6.9725e-07,  ...,  3.0113e-05,\n",
      "         -8.4207e-07,  4.6915e-05],\n",
      "        [-1.5285e-05, -5.0095e-05,  6.9824e-07,  ...,  3.0125e-05,\n",
      "         -8.4276e-07,  4.6919e-05]], device='cuda:0')\n",
      "219.4800567626953\n",
      "tensor([[-6.7026e-06, -3.8768e-05, -9.0247e-08,  ...,  7.3020e-05,\n",
      "         -1.6340e-06,  1.2252e-04],\n",
      "        [-6.7193e-06, -3.8791e-05, -8.6136e-08,  ...,  7.3002e-05,\n",
      "         -1.6321e-06,  1.2260e-04],\n",
      "        [-6.7310e-06, -3.8776e-05, -8.5167e-08,  ...,  7.3009e-05,\n",
      "         -1.6271e-06,  1.2264e-04],\n",
      "        ...,\n",
      "        [-7.6462e-06, -3.9047e-05,  2.3552e-07,  ...,  7.2226e-05,\n",
      "         -1.4046e-06,  1.2570e-04],\n",
      "        [-7.6544e-06, -3.9054e-05,  2.4325e-07,  ...,  7.2176e-05,\n",
      "         -1.3988e-06,  1.2572e-04],\n",
      "        [-7.6615e-06, -3.9074e-05,  2.4426e-07,  ...,  7.2169e-05,\n",
      "         -1.3993e-06,  1.2570e-04]], device='cuda:0')\n",
      "218.004638671875\n",
      "tensor([[-8.5638e-06, -2.4681e-05, -1.6994e-08,  ...,  8.2207e-05,\n",
      "         -1.5579e-06,  9.4825e-05],\n",
      "        [-8.5759e-06, -2.4692e-05, -1.3175e-08,  ...,  8.2176e-05,\n",
      "         -1.5572e-06,  9.4933e-05],\n",
      "        [-8.5896e-06, -2.4677e-05, -1.3889e-08,  ...,  8.2210e-05,\n",
      "         -1.5541e-06,  9.4987e-05],\n",
      "        ...,\n",
      "        [-9.2537e-06, -2.4850e-05,  2.4374e-07,  ...,  8.1744e-05,\n",
      "         -1.4128e-06,  9.7586e-05],\n",
      "        [-9.2634e-06, -2.4857e-05,  2.4898e-07,  ...,  8.1682e-05,\n",
      "         -1.4081e-06,  9.7595e-05],\n",
      "        [-9.2677e-06, -2.4863e-05,  2.5051e-07,  ...,  8.1690e-05,\n",
      "         -1.4078e-06,  9.7600e-05]], device='cuda:0')\n",
      "236.51951599121094\n",
      "tensor([[ 1.0809e-06, -1.5531e-05,  1.6702e-07,  ...,  6.9026e-05,\n",
      "         -9.0137e-07, -6.3044e-05],\n",
      "        [ 1.0730e-06, -1.5540e-05,  1.6694e-07,  ...,  6.9007e-05,\n",
      "         -9.0308e-07, -6.2858e-05],\n",
      "        [ 1.0645e-06, -1.5530e-05,  1.6627e-07,  ...,  6.9056e-05,\n",
      "         -9.0280e-07, -6.2900e-05],\n",
      "        ...,\n",
      "        [ 5.7548e-07, -1.5702e-05,  3.5852e-07,  ...,  6.8523e-05,\n",
      "         -8.0537e-07, -5.9954e-05],\n",
      "        [ 5.6834e-07, -1.5706e-05,  3.6645e-07,  ...,  6.8480e-05,\n",
      "         -8.0042e-07, -5.9909e-05],\n",
      "        [ 5.6562e-07, -1.5715e-05,  3.6630e-07,  ...,  6.8495e-05,\n",
      "         -8.0265e-07, -5.9910e-05]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217.96560668945312\n",
      "tensor([[ 1.1078e-06, -4.6604e-06,  3.7407e-07,  ...,  2.0958e-05,\n",
      "         -6.1355e-07, -1.3685e-04],\n",
      "        [ 1.1044e-06, -4.6465e-06,  3.7426e-07,  ...,  2.0969e-05,\n",
      "         -6.1381e-07, -1.3670e-04],\n",
      "        [ 1.0947e-06, -4.6471e-06,  3.7191e-07,  ...,  2.0990e-05,\n",
      "         -6.1412e-07, -1.3671e-04],\n",
      "        ...,\n",
      "        [ 7.1635e-07, -4.7751e-06,  5.1516e-07,  ...,  2.0429e-05,\n",
      "         -5.5896e-07, -1.3359e-04],\n",
      "        [ 7.0866e-07, -4.7755e-06,  5.2146e-07,  ...,  2.0397e-05,\n",
      "         -5.5451e-07, -1.3353e-04],\n",
      "        [ 7.0681e-07, -4.7794e-06,  5.2241e-07,  ...,  2.0423e-05,\n",
      "         -5.5481e-07, -1.3354e-04]], device='cuda:0')\n",
      "217.97120666503906\n",
      "tensor([[-8.8126e-07,  4.2610e-06,  5.2992e-07,  ..., -2.4921e-05,\n",
      "         -8.8927e-07, -1.2714e-04],\n",
      "        [-8.8756e-07,  4.2625e-06,  5.3157e-07,  ..., -2.4916e-05,\n",
      "         -8.8983e-07, -1.2695e-04],\n",
      "        [-8.9275e-07,  4.2646e-06,  5.2891e-07,  ..., -2.4884e-05,\n",
      "         -8.9024e-07, -1.2698e-04],\n",
      "        ...,\n",
      "        [-1.1848e-06,  4.1900e-06,  6.3526e-07,  ..., -2.5484e-05,\n",
      "         -8.6902e-07, -1.2397e-04],\n",
      "        [-1.1930e-06,  4.1799e-06,  6.4101e-07,  ..., -2.5499e-05,\n",
      "         -8.6489e-07, -1.2387e-04],\n",
      "        [-1.1899e-06,  4.1838e-06,  6.3897e-07,  ..., -2.5475e-05,\n",
      "         -8.6561e-07, -1.2391e-04]], device='cuda:0')\n",
      "217.8966064453125\n",
      "tensor([[ 2.0059e-06,  1.1500e-05,  6.1747e-07,  ..., -4.2663e-05,\n",
      "         -5.2109e-07, -1.1310e-04],\n",
      "        [ 2.0075e-06,  1.1504e-05,  6.1480e-07,  ..., -4.2631e-05,\n",
      "         -5.2385e-07, -1.1294e-04],\n",
      "        [ 2.0021e-06,  1.1506e-05,  6.1209e-07,  ..., -4.2610e-05,\n",
      "         -5.2529e-07, -1.1298e-04],\n",
      "        ...,\n",
      "        [ 1.7871e-06,  1.1489e-05,  6.8646e-07,  ..., -4.3188e-05,\n",
      "         -5.2206e-07, -1.1016e-04],\n",
      "        [ 1.7793e-06,  1.1478e-05,  6.8891e-07,  ..., -4.3209e-05,\n",
      "         -5.2002e-07, -1.1008e-04],\n",
      "        [ 1.7828e-06,  1.1480e-05,  6.8822e-07,  ..., -4.3170e-05,\n",
      "         -5.2076e-07, -1.1006e-04]], device='cuda:0')\n",
      "218.3428497314453\n",
      "tensor([[ 4.4117e-06,  1.8267e-05,  5.0670e-07,  ..., -4.4185e-05,\n",
      "         -5.7934e-07, -5.9373e-05],\n",
      "        [ 4.4131e-06,  1.8270e-05,  5.0477e-07,  ..., -4.4181e-05,\n",
      "         -5.8172e-07, -5.9239e-05],\n",
      "        [ 4.4107e-06,  1.8272e-05,  5.0041e-07,  ..., -4.4149e-05,\n",
      "         -5.8247e-07, -5.9253e-05],\n",
      "        ...,\n",
      "        [ 4.2417e-06,  1.8290e-05,  5.5756e-07,  ..., -4.4669e-05,\n",
      "         -5.9040e-07, -5.6625e-05],\n",
      "        [ 4.2339e-06,  1.8283e-05,  5.6089e-07,  ..., -4.4665e-05,\n",
      "         -5.8951e-07, -5.6511e-05],\n",
      "        [ 4.2375e-06,  1.8291e-05,  5.6076e-07,  ..., -4.4634e-05,\n",
      "         -5.8964e-07, -5.6494e-05]], device='cuda:0')\n",
      "218.10914611816406\n",
      "tensor([[ 1.5829e-07,  2.3152e-05,  5.3330e-07,  ..., -4.7716e-05,\n",
      "         -8.8662e-07,  6.0878e-05],\n",
      "        [ 1.5814e-07,  2.3161e-05,  5.3235e-07,  ..., -4.7676e-05,\n",
      "         -8.8771e-07,  6.0996e-05],\n",
      "        [ 1.5334e-07,  2.3163e-05,  5.3215e-07,  ..., -4.7650e-05,\n",
      "         -8.8749e-07,  6.1070e-05],\n",
      "        ...,\n",
      "        [-2.2322e-08,  2.3193e-05,  5.8853e-07,  ..., -4.8156e-05,\n",
      "         -9.0352e-07,  6.3599e-05],\n",
      "        [-2.9873e-08,  2.3178e-05,  5.9267e-07,  ..., -4.8178e-05,\n",
      "         -9.0188e-07,  6.3615e-05],\n",
      "        [-2.6555e-08,  2.3187e-05,  5.9247e-07,  ..., -4.8148e-05,\n",
      "         -9.0170e-07,  6.3673e-05]], device='cuda:0')\n",
      "218.09152221679688\n",
      "tensor([[-2.2788e-06,  2.0765e-05,  5.8768e-07,  ..., -3.7732e-05,\n",
      "         -6.3771e-07,  1.1998e-04],\n",
      "        [-2.2810e-06,  2.0762e-05,  5.8594e-07,  ..., -3.7700e-05,\n",
      "         -6.3930e-07,  1.2010e-04],\n",
      "        [-2.2830e-06,  2.0775e-05,  5.8166e-07,  ..., -3.7684e-05,\n",
      "         -6.4140e-07,  1.2014e-04],\n",
      "        ...,\n",
      "        [-2.4894e-06,  2.0816e-05,  6.4198e-07,  ..., -3.8208e-05,\n",
      "         -6.5240e-07,  1.2271e-04],\n",
      "        [-2.5011e-06,  2.0798e-05,  6.4695e-07,  ..., -3.8226e-05,\n",
      "         -6.4989e-07,  1.2267e-04],\n",
      "        [-2.4985e-06,  2.0812e-05,  6.4464e-07,  ..., -3.8191e-05,\n",
      "         -6.5144e-07,  1.2272e-04]], device='cuda:0')\n",
      "218.14883422851562\n",
      "tensor([[ 8.8125e-07,  1.3079e-05,  4.2295e-07,  ..., -1.3918e-05,\n",
      "         -5.6322e-08,  7.2516e-05],\n",
      "        [ 8.7967e-07,  1.3089e-05,  4.2159e-07,  ..., -1.3886e-05,\n",
      "         -5.7233e-08,  7.2701e-05],\n",
      "        [ 8.7640e-07,  1.3098e-05,  4.1916e-07,  ..., -1.3874e-05,\n",
      "         -5.7749e-08,  7.2720e-05],\n",
      "        ...,\n",
      "        [ 6.4636e-07,  1.3124e-05,  4.7371e-07,  ..., -1.4327e-05,\n",
      "         -5.5509e-08,  7.5263e-05],\n",
      "        [ 6.4012e-07,  1.3114e-05,  4.7947e-07,  ..., -1.4355e-05,\n",
      "         -5.2892e-08,  7.5288e-05],\n",
      "        [ 6.4006e-07,  1.3125e-05,  4.7783e-07,  ..., -1.4333e-05,\n",
      "         -5.4107e-08,  7.5317e-05]], device='cuda:0')\n",
      "218.071044921875\n",
      "tensor([[3.2034e-06, 6.2041e-06, 1.8578e-07,  ..., 4.7112e-06, 1.8847e-07,\n",
      "         1.0582e-05],\n",
      "        [3.2013e-06, 6.2080e-06, 1.8263e-07,  ..., 4.7397e-06, 1.8574e-07,\n",
      "         1.0663e-05],\n",
      "        [3.2024e-06, 6.2174e-06, 1.8248e-07,  ..., 4.7583e-06, 1.8490e-07,\n",
      "         1.0740e-05],\n",
      "        ...,\n",
      "        [2.9605e-06, 6.2364e-06, 2.2783e-07,  ..., 4.4001e-06, 2.0031e-07,\n",
      "         1.3232e-05],\n",
      "        [2.9472e-06, 6.2280e-06, 2.3708e-07,  ..., 4.3513e-06, 2.0591e-07,\n",
      "         1.3210e-05],\n",
      "        [2.9481e-06, 6.2326e-06, 2.3308e-07,  ..., 4.3806e-06, 2.0399e-07,\n",
      "         1.3243e-05]], device='cuda:0')\n",
      "218.66310119628906\n",
      "tensor([[ 1.5510e-07,  1.5980e-06,  1.1842e-07,  ...,  9.9062e-06,\n",
      "          2.3172e-07,  9.4932e-06],\n",
      "        [ 1.5329e-07,  1.5981e-06,  1.1702e-07,  ...,  9.9420e-06,\n",
      "          2.3046e-07,  9.6519e-06],\n",
      "        [ 1.5230e-07,  1.6092e-06,  1.1399e-07,  ...,  9.9726e-06,\n",
      "          2.2792e-07,  9.6854e-06],\n",
      "        ...,\n",
      "        [-1.0143e-07,  1.6222e-06,  1.5953e-07,  ...,  9.6813e-06,\n",
      "          2.5429e-07,  1.2120e-05],\n",
      "        [-1.1268e-07,  1.6131e-06,  1.6646e-07,  ...,  9.6294e-06,\n",
      "          2.5812e-07,  1.2044e-05],\n",
      "        [-1.1312e-07,  1.6191e-06,  1.6238e-07,  ...,  9.6577e-06,\n",
      "          2.5588e-07,  1.2110e-05]], device='cuda:0')\n",
      "217.92684936523438\n",
      "tensor([[-2.5387e-06, -1.6648e-06,  8.1883e-08,  ...,  9.7807e-06,\n",
      "          6.2768e-07,  1.6180e-05],\n",
      "        [-2.5463e-06, -1.6629e-06,  7.9154e-08,  ...,  9.7863e-06,\n",
      "          6.2665e-07,  1.6309e-05],\n",
      "        [-2.5444e-06, -1.6525e-06,  7.7151e-08,  ...,  9.8258e-06,\n",
      "          6.2510e-07,  1.6335e-05],\n",
      "        ...,\n",
      "        [-2.7905e-06, -1.6426e-06,  1.1654e-07,  ...,  9.6268e-06,\n",
      "          6.5627e-07,  1.8620e-05],\n",
      "        [-2.8021e-06, -1.6517e-06,  1.2459e-07,  ...,  9.5843e-06,\n",
      "          6.6177e-07,  1.8609e-05],\n",
      "        [-2.8050e-06, -1.6489e-06,  1.2116e-07,  ...,  9.6035e-06,\n",
      "          6.5970e-07,  1.8684e-05]], device='cuda:0')\n",
      "217.94256591796875\n",
      "tensor([[ 1.2562e-07, -2.4315e-06, -1.5307e-07,  ...,  1.5634e-05,\n",
      "          8.4902e-07, -2.8531e-05],\n",
      "        [ 1.2145e-07, -2.4303e-06, -1.5546e-07,  ...,  1.5643e-05,\n",
      "          8.4781e-07, -2.8396e-05],\n",
      "        [ 1.2253e-07, -2.4201e-06, -1.5620e-07,  ...,  1.5696e-05,\n",
      "          8.4740e-07, -2.8326e-05],\n",
      "        ...,\n",
      "        [-1.0038e-07, -2.4087e-06, -1.2494e-07,  ...,  1.5571e-05,\n",
      "          8.8252e-07, -2.6140e-05],\n",
      "        [-1.1066e-07, -2.4165e-06, -1.1761e-07,  ...,  1.5516e-05,\n",
      "          8.8650e-07, -2.6183e-05],\n",
      "        [-1.1159e-07, -2.4120e-06, -1.2038e-07,  ...,  1.5539e-05,\n",
      "          8.8565e-07, -2.6159e-05]], device='cuda:0')\n",
      "217.98294067382812\n",
      "tensor([[ 8.3601e-07, -1.4757e-06, -2.9321e-07,  ...,  1.5112e-05,\n",
      "          5.6565e-07, -3.9485e-05],\n",
      "        [ 8.3386e-07, -1.4732e-06, -2.9613e-07,  ...,  1.5130e-05,\n",
      "          5.6600e-07, -3.9400e-05],\n",
      "        [ 8.3535e-07, -1.4627e-06, -2.9786e-07,  ...,  1.5176e-05,\n",
      "          5.6429e-07, -3.9315e-05],\n",
      "        ...,\n",
      "        [ 6.2650e-07, -1.4467e-06, -2.6926e-07,  ...,  1.5056e-05,\n",
      "          5.9559e-07, -3.7306e-05],\n",
      "        [ 6.1532e-07, -1.4520e-06, -2.6138e-07,  ...,  1.4994e-05,\n",
      "          6.0009e-07, -3.7362e-05],\n",
      "        [ 6.1832e-07, -1.4496e-06, -2.6685e-07,  ...,  1.5048e-05,\n",
      "          5.9956e-07, -3.7282e-05]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "rnn.train()\n",
    "iteration = 0\n",
    "# how often we plot the prediction\n",
    "log_iter = 10\n",
    "iter_loss = []\n",
    "\n",
    "# train for a set number of iterations\n",
    "for iteration in range(n_iterations):\n",
    "\n",
    "    # generates a long time series / normally loaded from dataset (e.g. stocks, weather)\n",
    "    x, y = generateData(\n",
    "        dims, signal_length, predict_ahead, signal_repeats, batch_size, noise_strength\n",
    "    )\n",
    "\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    h = c = None\n",
    "    # reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "#    t0 = time.time()\n",
    "    start.record()\n",
    "\n",
    "    # get predictions (forward pass)\n",
    "    y_hat, h, c = rnn(x, h, c)\n",
    "           \n",
    "    # calculate mean squared error\n",
    "    loss = torch.mean((y_hat - y)**2)        \n",
    "    # backprop\n",
    "    loss.backward()\n",
    "\n",
    "    end.record()\n",
    "#    torch.cuda.current_stream().synchronize()\n",
    "#    t1 = time.time()\n",
    "#    print(t1-t0)\n",
    "\n",
    "    # Waits for everything to finish running\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    print(start.elapsed_time(end))\n",
    "\n",
    "    print(rnn.W_o.grad)\n",
    "    # finally we are adapting the weights with the saved gradient information\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    # log loss\n",
    "#    iter_loss.append(loss.item())\n",
    "    \n",
    "    # plot model predictions during training\n",
    "#    if iteration % log_iter == 0:\n",
    "#        replot(x[0].cpu(), y_hat[0].detach().cpu(), \n",
    "#               y[0].cpu(), iteration + 1, iter_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57763251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db6482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
